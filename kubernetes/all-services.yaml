# Copyright The OpenTelemetry Authors
# SPDX-License-Identifier: Apache-2.0
# This file is generated by 'make generate-kubernetes-manifests'
---
apiVersion: v1
kind: Namespace
metadata:
  name: otel-demo
---
# Source: opentelemetry-demo/charts/opensearch/templates/poddisruptionbudget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: "opensearch-pdb"
  labels:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.19.0"
    app.kubernetes.io/component: opensearch
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: opentelemetry-demo
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: otel-demo
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.120.0"
    app.kubernetes.io/component: standalone-collector
---
# Source: opentelemetry-demo/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: opentelemetry-demo
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
---
# Source: opentelemetry-demo/charts/opensearch/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opensearch-config
  labels:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.19.0"
    app.kubernetes.io/component: opensearch
data:
  opensearch.yml: |
    cluster.name: opensearch-cluster

    # Bind to all interfaces because we don't know what IP address Docker will assign to us.
    network.host: 0.0.0.0

    # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
    # Implicitly done if ".singleNode" is set to "true".
    # discovery.type: single-node

    # Start OpenSearch Security Demo Configuration
    # WARNING: revise all the lines below before you go into production
    # plugins:
    #   security:
    #     ssl:
    #       transport:
    #         pemcert_filepath: esnode.pem
    #         pemkey_filepath: esnode-key.pem
    #         pemtrustedcas_filepath: root-ca.pem
    #         enforce_hostname_verification: false
    #       http:
    #         enabled: true
    #         pemcert_filepath: esnode.pem
    #         pemkey_filepath: esnode-key.pem
    #         pemtrustedcas_filepath: root-ca.pem
    #     allow_unsafe_democertificates: true
    #     allow_default_init_securityindex: true
    #     authcz:
    #       admin_dn:
    #         - CN=kirk,OU=client,O=client,L=test,C=de
    #     audit.type: internal_opensearch
    #     enable_snapshot_restore_privilege: true
    #     check_snapshot_restore_write_privileges: true
    #     restapi:
    #       roles_enabled: ["all_access", "security_rest_api_access"]
    #     system_indices:
    #       enabled: true
    #       indices:
    #         [
    #           ".opendistro-alerting-config",
    #           ".opendistro-alerting-alert*",
    #           ".opendistro-anomaly-results*",
    #           ".opendistro-anomaly-detector*",
    #           ".opendistro-anomaly-checkpoints",
    #           ".opendistro-anomaly-detection-state",
    #           ".opendistro-reports-*",
    #           ".opendistro-notifications-*",
    #           ".opendistro-notebooks",
    #           ".opendistro-asynchronous-search-response*",
    #         ]
    ######## End OpenSearch Security Demo Configuration ########
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector
  namespace: otel-demo
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.120.0"
    app.kubernetes.io/component: standalone-collector
data:
  relay: |
    connectors:
      spanmetrics: {}
    exporters:
      debug: {}
      opensearch:
        http:
          endpoint: http://opensearch:9200
          tls:
            insecure: true
        logs_index: otel
      otlp:
        endpoint: jaeger-collector:4317
        tls:
          insecure: true
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        tls:
          insecure: true
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
    processors:
      batch: {}
      k8sattributes:
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource:
        attributes:
        - action: insert
          from_attribute: k8s.pod.uid
          key: service.instance.id
      transform:
        error_mode: ignore
        trace_statements:
        - context: span
          statements:
          - replace_pattern(name, "\\?.*", "")
          - replace_match(name, "GET /api/products/*", "GET /api/products/{productId}")
    receivers:
      httpcheck/frontend-proxy:
        targets:
        - endpoint: http://frontend-proxy:8080
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            cors:
              allowed_origins:
              - http://*
              - https://*
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      redis:
        collection_interval: 10s
        endpoint: valkey-cart:6379
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
    service:
      extensions:
      - health_check
      pipelines:
        logs:
          exporters:
          - opensearch
          - debug
          processors:
          - k8sattributes
          - memory_limiter
          - resource
          - batch
          receivers:
          - otlp
        metrics:
          exporters:
          - otlphttp/prometheus
          - debug
          processors:
          - k8sattributes
          - memory_limiter
          - resource
          - batch
          receivers:
          - httpcheck/frontend-proxy
          - redis
          - otlp
          - spanmetrics
        traces:
          exporters:
          - otlp
          - debug
          - spanmetrics
          processors:
          - k8sattributes
          - memory_limiter
          - resource
          - transform
          - batch
          receivers:
          - otlp
          - jaeger
          - zipkin
      telemetry:
        metrics:
          address: ${env:MY_POD_IP}:8888
          level: detailed
          readers:
          - periodic:
              exporter:
                otlp:
                  endpoint: otel-collector:4318
                  protocol: grpc
              interval: 10000
              timeout: 5000
---
# Source: opentelemetry-demo/templates/flagd-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flagd-config
  namespace: otel-demo
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
data:
  demo.flagd.json: |
    {
      "$schema": "https://flagd.dev/schema/v0/flags.json",
      "flags": {
        "productCatalogFailure": {
          "description": "Fail product catalog service on a specific product",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "recommendationCacheFailure": {
          "description": "Fail recommendation service cache",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adManualGc": {
          "description": "Triggers full manual garbage collections in the ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adHighCpu": {
          "description": "Triggers high cpu load in the ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adFailure": {
          "description": "Fail ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "kafkaQueueProblems": {
          "description": "Overloads Kafka queue while simultaneously introducing a consumer side delay leading to a lag spike",
          "state": "ENABLED",
          "variants": {
            "on": 100,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "cartFailure": {
          "description": "Fail cart service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "paymentFailure": {
          "description": "Fail payment service charge requests n%",
          "state": "ENABLED",
          "variants": {
            "100%": 1,
            "90%": 0.95,
            "75%": 0.75,
            "50%": 0.5,
            "25%": 0.25,
            "10%": 0.1,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "paymentUnreachable": {
          "description": "Payment service is unavailable",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "loadGeneratorFloodHomepage": {
          "description": "Flood the frontend with a large amount of requests.",
          "state": "ENABLED",
          "variants": {
            "on": 100,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "imageSlowLoad": {
          "description": "slow loading images in the frontend",
          "state": "ENABLED",
          "variants": {
            "10sec": 10000,
            "5sec": 5000,
            "off": 0
          },
          "defaultVariant": "off"
        }
      }
    }

---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.120.0"
    app.kubernetes.io/component: standalone-collector
rules:
  - apiGroups: [""]
    resources: ["pods", "namespaces"]
    verbs: ["get", "watch", "list"]
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.120.0"
    app.kubernetes.io/component: standalone-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
  - kind: ServiceAccount
    name: otel-collector
    namespace: otel-demo
---
# Source: opentelemetry-demo/charts/opensearch/templates/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: opensearch
  labels:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.19.0"
    app.kubernetes.io/component: opensearch
  annotations: {}
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
  ports:
    - name: http
      protocol: TCP
      port: 9200
    - name: transport
      protocol: TCP
      port: 9300
    - name: metrics
      protocol: TCP
      port: 9600
---
# Source: opentelemetry-demo/charts/opensearch/templates/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: opensearch-headless
  labels:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.19.0"
    app.kubernetes.io/component: opensearch
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None # This is needed for statefulset hostnames like opensearch-0 to resolve
  # Create endpoints also if the related pod isn't ready
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
  ports:
    - name: http
      port: 9200
    - name: transport
      port: 9300
    - name: metrics
      port: 9600
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: otel-demo
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.120.0"
    app.kubernetes.io/component: standalone-collector
    component: standalone-collector
spec:
  type: ClusterIP
  ports:
    - name: jaeger-compact
      port: 6831
      targetPort: 6831
      protocol: UDP
    - name: jaeger-grpc
      port: 14250
      targetPort: 14250
      protocol: TCP
    - name: jaeger-thrift
      port: 14268
      targetPort: 14268
      protocol: TCP
    - name: metrics
      port: 8888
      targetPort: 8888
      protocol: TCP
    - name: otlp
      port: 4317
      targetPort: 4317
      protocol: TCP
      appProtocol: grpc
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
    - name: zipkin
      port: 9411
      targetPort: 9411
      protocol: TCP
  selector:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    component: standalone-collector
  internalTrafficPolicy: Cluster
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: cart
  labels:
    opentelemetry.io/name: cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: cart
    app.kubernetes.io/name: cart
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: cart
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: checkout
  labels:
    opentelemetry.io/name: checkout
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: checkout
    app.kubernetes.io/name: checkout
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: checkout
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: currency
  labels:
    opentelemetry.io/name: currency
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: currency
    app.kubernetes.io/name: currency
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: currency
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: email
  labels:
    opentelemetry.io/name: email
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: email
    app.kubernetes.io/name: email
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: email
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: flagd
  labels:
    opentelemetry.io/name: flagd
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: flagd
    app.kubernetes.io/name: flagd
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8013
      name: rpc
      targetPort: 8013
    - port: 8016
      name: ofrep
      targetPort: 8016
    - port: 4000
      name: tcp-service-0
      targetPort: 4000
  selector:
    opentelemetry.io/name: flagd
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    opentelemetry.io/name: frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: frontend
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: frontend
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-proxy
  labels:
    opentelemetry.io/name: frontend-proxy
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend-proxy
    app.kubernetes.io/name: frontend-proxy
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: frontend-proxy
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: image-provider
  labels:
    opentelemetry.io/name: image-provider
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: image-provider
    app.kubernetes.io/name: image-provider
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8081
      name: tcp-service
      targetPort: 8081
  selector:
    opentelemetry.io/name: image-provider
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
  labels:
    opentelemetry.io/name: kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 9092
      name: plaintext
      targetPort: 9092
    - port: 9093
      name: controller
      targetPort: 9093
  selector:
    opentelemetry.io/name: kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: load-generator
  labels:
    opentelemetry.io/name: load-generator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: load-generator
    app.kubernetes.io/name: load-generator
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8089
      name: tcp-service
      targetPort: 8089
  selector:
    opentelemetry.io/name: load-generator
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: payment
  labels:
    opentelemetry.io/name: payment
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: payment
    app.kubernetes.io/name: payment
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: payment
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: quote
  labels:
    opentelemetry.io/name: quote
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: quote
    app.kubernetes.io/name: quote
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: quote
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: shipping
  labels:
    opentelemetry.io/name: shipping
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: shipping
    app.kubernetes.io/name: shipping
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: shipping
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: valkey-cart
  labels:
    opentelemetry.io/name: valkey-cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: valkey-cart
    app.kubernetes.io/name: valkey-cart
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 6379
      name: valkey-cart
      targetPort: 6379
  selector:
    opentelemetry.io/name: valkey-cart
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: otel-demo
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.120.0"
    app.kubernetes.io/component: standalone-collector
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: opentelemetry-collector
      app.kubernetes.io/instance: opentelemetry-demo
      component: standalone-collector
  strategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: a89266db0e62ae4711e3cef2ea43e19dac4d19232eb4bb06b05882a36f128110
        opentelemetry_community_demo: "true"
        prometheus.io/scrape: "true"
      labels:
        app.kubernetes.io/name: opentelemetry-collector
        app.kubernetes.io/instance: opentelemetry-demo
        component: standalone-collector

    spec:
      serviceAccountName: otel-collector
      securityContext: {}
      containers:
        - name: opentelemetry-collector
          args:
            - --config=/conf/relay.yaml
          securityContext: {}
          image: "otel/opentelemetry-collector-contrib:0.120.0"
          imagePullPolicy: IfNotPresent
          ports:
            - name: jaeger-compact
              containerPort: 6831
              protocol: UDP
            - name: jaeger-grpc
              containerPort: 14250
              protocol: TCP
            - name: jaeger-thrift
              containerPort: 14268
              protocol: TCP
            - name: metrics
              containerPort: 8888
              protocol: TCP
            - name: otlp
              containerPort: 4317
              protocol: TCP
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
            - name: zipkin
              containerPort: 9411
              protocol: TCP
          env:
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: GOMEMLIMIT
              value: "160MiB"
          livenessProbe:
            httpGet:
              path: /
              port: 13133
          readinessProbe:
            httpGet:
              path: /
              port: 13133
          resources:
            limits:
              memory: 200Mi
          volumeMounts:
            - mountPath: /conf
              name: opentelemetry-collector-configmap
      volumes:
        - name: opentelemetry-collector-configmap
          configMap:
            name: otel-collector
            items:
              - key: relay
                path: relay.yaml
      hostNetwork: false
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: accounting
  labels:
    opentelemetry.io/name: accounting
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: accounting
    app.kubernetes.io/name: accounting
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: accounting
  template:
    metadata:
      labels:
        opentelemetry.io/name: accounting
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: accounting
        app.kubernetes.io/name: accounting
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: accounting
          image: "ghcr.io/open-telemetry/demo:2.0.2-accounting"
          imagePullPolicy: IfNotPresent
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: KAFKA_ADDR
              value: kafka:9092
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 120Mi
          volumeMounts:
      initContainers:
        - command:
            - sh
            - -c
            - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cart
  labels:
    opentelemetry.io/name: cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: cart
    app.kubernetes.io/name: cart
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: cart
  template:
    metadata:
      labels:
        opentelemetry.io/name: cart
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: cart
        app.kubernetes.io/name: cart
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: cart
          image: "ghcr.io/open-telemetry/demo:2.0.2-cart"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: CART_PORT
              value: "8080"
            - name: ASPNETCORE_URLS
              value: http://*:$(CART_PORT)
            - name: VALKEY_ADDR
              value: valkey-cart:6379
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 160Mi
          volumeMounts:
      initContainers:
        - command:
            - sh
            - -c
            - until nc -z -v -w30 valkey-cart 6379; do echo waiting for valkey-cart; sleep 2;
              done;
          image: busybox:latest
          name: wait-for-valkey-cart
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: checkout
  labels:
    opentelemetry.io/name: checkout
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: checkout
    app.kubernetes.io/name: checkout
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: checkout
  template:
    metadata:
      labels:
        opentelemetry.io/name: checkout
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: checkout
        app.kubernetes.io/name: checkout
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: checkout
          image: "ghcr.io/open-telemetry/demo:2.0.2-checkout"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: CHECKOUT_PORT
              value: "8080"
            - name: CART_ADDR
              value: cart:8080
            - name: CURRENCY_ADDR
              value: currency:8080
            - name: EMAIL_ADDR
              value: http://email:8080
            - name: PAYMENT_ADDR
              value: payment:8080
            - name: PRODUCT_CATALOG_ADDR
              value: product-catalog:8080
            - name: SHIPPING_ADDR
              value: shipping:8080
            - name: KAFKA_ADDR
              value: kafka:9092
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      initContainers:
        - command:
            - sh
            - -c
            - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: currency
  labels:
    opentelemetry.io/name: currency
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: currency
    app.kubernetes.io/name: currency
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: currency
  template:
    metadata:
      labels:
        opentelemetry.io/name: currency
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: currency
        app.kubernetes.io/name: currency
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: currency
          image: "ghcr.io/open-telemetry/demo:2.0.2-currency"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: CURRENCY_PORT
              value: "8080"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: VERSION
              value: "2.0.2"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: email
  labels:
    opentelemetry.io/name: email
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: email
    app.kubernetes.io/name: email
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: email
  template:
    metadata:
      labels:
        opentelemetry.io/name: email
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: email
        app.kubernetes.io/name: email
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: email
          image: "ghcr.io/open-telemetry/demo:2.0.2-email"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: EMAIL_PORT
              value: "8080"
            - name: APP_ENV
              value: production
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 100Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flagd
  labels:
    opentelemetry.io/name: flagd
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: flagd
    app.kubernetes.io/name: flagd
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: flagd
  template:
    metadata:
      labels:
        opentelemetry.io/name: flagd
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: flagd
        app.kubernetes.io/name: flagd
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: flagd
          image: "ghcr.io/open-feature/flagd:v0.11.1"
          imagePullPolicy: IfNotPresent
          command:
            - /flagd-build
            - start
            - --port
            - "8013"
            - --ofrep-port
            - "8016"
            - --uri
            - file:./etc/flagd/demo.flagd.json
          ports:
            - containerPort: 8013
              name: rpc
            - containerPort: 8016
              name: ofrep
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: FLAGD_METRICS_EXPORTER
              value: otel
            - name: FLAGD_OTEL_COLLECTOR_URI
              value: $(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 75Mi
          volumeMounts:
            - name: config-rw
              mountPath: /etc/flagd
        - name: flagd-ui
          image: "ghcr.io/open-telemetry/demo:2.0.2-flagd-ui"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 4000
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: FLAGD_METRICS_EXPORTER
              value: otel
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 100Mi
          volumeMounts:
            - mountPath: /app/data
              name: config-rw
      initContainers:
        - command:
            - sh
            - -c
            - cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json
          image: busybox
          name: init-config
          volumeMounts:
            - mountPath: /config-ro
              name: config-ro
            - mountPath: /config-rw
              name: config-rw
      volumes:
        - name: config-rw
          emptyDir: {}
        - configMap:
            name: flagd-config
          name: config-ro
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fraud-detection
  labels:
    opentelemetry.io/name: fraud-detection
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: fraud-detection
    app.kubernetes.io/name: fraud-detection
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: fraud-detection
  template:
    metadata:
      labels:
        opentelemetry.io/name: fraud-detection
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: fraud-detection
        app.kubernetes.io/name: fraud-detection
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: fraud-detection
          image: "ghcr.io/open-telemetry/demo:2.0.2-fraud-detection"
          imagePullPolicy: IfNotPresent
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: KAFKA_ADDR
              value: kafka:9092
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 300Mi
          volumeMounts:
      initContainers:
        - command:
            - sh
            - -c
            - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:
    opentelemetry.io/name: frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: frontend
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: frontend
  template:
    metadata:
      labels:
        opentelemetry.io/name: frontend
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frontend
        app.kubernetes.io/name: frontend
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontend
          image: "ghcr.io/open-telemetry/demo:2.0.2-frontend"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: FRONTEND_PORT
              value: "8080"
            - name: FRONTEND_ADDR
              value: :8080
            - name: AD_ADDR
              value: ad:8080
            - name: CART_ADDR
              value: cart:8080
            - name: CHECKOUT_ADDR
              value: checkout:8080
            - name: CURRENCY_ADDR
              value: currency:8080
            - name: PRODUCT_CATALOG_ADDR
              value: product-catalog:8080
            - name: RECOMMENDATION_ADDR
              value: recommendation:8080
            - name: SHIPPING_ADDR
              value: shipping:8080
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_COLLECTOR_HOST
              value: $(OTEL_COLLECTOR_NAME)
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: WEB_OTEL_SERVICE_NAME
              value: frontend-web
            - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://localhost:8080/otlp-http/v1/traces
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 250Mi
          securityContext:
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-proxy
  labels:
    opentelemetry.io/name: frontend-proxy
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend-proxy
    app.kubernetes.io/name: frontend-proxy
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: frontend-proxy
  template:
    metadata:
      labels:
        opentelemetry.io/name: frontend-proxy
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frontend-proxy
        app.kubernetes.io/name: frontend-proxy
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontend-proxy
          image: "ghcr.io/open-telemetry/demo:2.0.2-frontend-proxy"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: ENVOY_PORT
              value: "8080"
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: FLAGD_UI_HOST
              value: flagd
            - name: FLAGD_UI_PORT
              value: "4000"
            - name: FRONTEND_HOST
              value: frontend
            - name: FRONTEND_PORT
              value: "8080"
            - name: GRAFANA_HOST
              value: grafana
            - name: GRAFANA_PORT
              value: "80"
            - name: IMAGE_PROVIDER_HOST
              value: image-provider
            - name: IMAGE_PROVIDER_PORT
              value: "8081"
            - name: JAEGER_HOST
              value: jaeger-query
            - name: JAEGER_PORT
              value: "16686"
            - name: LOCUST_WEB_HOST
              value: load-generator
            - name: LOCUST_WEB_PORT
              value: "8089"
            - name: OTEL_COLLECTOR_HOST
              value: $(OTEL_COLLECTOR_NAME)
            - name: OTEL_COLLECTOR_PORT_GRPC
              value: "4317"
            - name: OTEL_COLLECTOR_PORT_HTTP
              value: "4318"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 65Mi
          securityContext:
            runAsGroup: 101
            runAsNonRoot: true
            runAsUser: 101
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: image-provider
  labels:
    opentelemetry.io/name: image-provider
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: image-provider
    app.kubernetes.io/name: image-provider
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: image-provider
  template:
    metadata:
      labels:
        opentelemetry.io/name: image-provider
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: image-provider
        app.kubernetes.io/name: image-provider
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: image-provider
          image: "ghcr.io/open-telemetry/demo:2.0.2-image-provider"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8081
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: IMAGE_PROVIDER_PORT
              value: "8081"
            - name: OTEL_COLLECTOR_PORT_GRPC
              value: "4317"
            - name: OTEL_COLLECTOR_HOST
              value: $(OTEL_COLLECTOR_NAME)
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 50Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  labels:
    opentelemetry.io/name: kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: kafka
  template:
    metadata:
      labels:
        opentelemetry.io/name: kafka
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: kafka
        app.kubernetes.io/name: kafka
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: kafka
          image: "ghcr.io/open-telemetry/demo:2.0.2-kafka"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9092
              name: plaintext
            - containerPort: 9093
              name: controller
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: KAFKA_ADVERTISED_LISTENERS
              value: PLAINTEXT://kafka:9092
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: KAFKA_HEAP_OPTS
              value: -Xmx400M -Xms400M
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 600Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: load-generator
  labels:
    opentelemetry.io/name: load-generator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: load-generator
    app.kubernetes.io/name: load-generator
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: load-generator
  template:
    metadata:
      labels:
        opentelemetry.io/name: load-generator
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: load-generator
        app.kubernetes.io/name: load-generator
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: load-generator
          image: "ghcr.io/open-telemetry/demo:2.0.2-load-generator"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8089
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: LOCUST_WEB_HOST
              value: 0.0.0.0
            - name: LOCUST_WEB_PORT
              value: "8089"
            - name: LOCUST_USERS
              value: "10"
            - name: LOCUST_SPAWN_RATE
              value: "1"
            - name: LOCUST_HOST
              value: http://frontend-proxy:8080
            - name: LOCUST_HEADLESS
              value: "false"
            - name: LOCUST_AUTOSTART
              value: "true"
            - name: LOCUST_BROWSER_TRAFFIC_ENABLED
              value: "true"
            - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
              value: python
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_OFREP_PORT
              value: "8016"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 1500Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment
  labels:
    opentelemetry.io/name: payment
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: payment
    app.kubernetes.io/name: payment
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: payment
  template:
    metadata:
      labels:
        opentelemetry.io/name: payment
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: payment
        app.kubernetes.io/name: payment
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: payment
          image: "ghcr.io/open-telemetry/demo:2.0.2-payment"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: PAYMENT_PORT
              value: "8080"
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 120Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: quote
  labels:
    opentelemetry.io/name: quote
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: quote
    app.kubernetes.io/name: quote
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: quote
  template:
    metadata:
      labels:
        opentelemetry.io/name: quote
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: quote
        app.kubernetes.io/name: quote
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: quote
          image: "ghcr.io/open-telemetry/demo:2.0.2-quote"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: QUOTE_PORT
              value: "8080"
            - name: OTEL_PHP_AUTOLOAD_ENABLED
              value: "true"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 40Mi
          securityContext:
            runAsGroup: 33
            runAsNonRoot: true
            runAsUser: 33
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: shipping
  labels:
    opentelemetry.io/name: shipping
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: shipping
    app.kubernetes.io/name: shipping
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: shipping
  template:
    metadata:
      labels:
        opentelemetry.io/name: shipping
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: shipping
        app.kubernetes.io/name: shipping
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: shipping
          image: "ghcr.io/open-telemetry/demo:2.0.2-shipping"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: SHIPPING_PORT
              value: "8080"
            - name: QUOTE_ADDR
              value: http://quote:8080
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: valkey-cart
  labels:
    opentelemetry.io/name: valkey-cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: valkey-cart
    app.kubernetes.io/name: valkey-cart
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: valkey-cart
  template:
    metadata:
      labels:
        opentelemetry.io/name: valkey-cart
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: valkey-cart
        app.kubernetes.io/name: valkey-cart
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: valkey-cart
          image: "valkey/valkey:7.2-alpine"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 6379
              name: valkey-cart
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: OTEL_COLLECTOR_NAME
              value: otel-collector
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
          resources:
            limits:
              memory: 20Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 999
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/charts/opensearch/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: opensearch
  labels:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "2.19.0"
    app.kubernetes.io/component: opensearch
  annotations:
    majorVersion: "2"
spec:
  serviceName: opensearch-headless
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: opentelemetry-demo
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: "opensearch"
      labels:
        app.kubernetes.io/name: opensearch
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/version: "2.19.0"
        app.kubernetes.io/component: opensearch
      annotations:
        configchecksum: 39d5e484f1cc28f685f786a856c4336341c6c034f5c0b1a81337e4a39511e47
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      automountServiceAccountToken: false
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/instance
                      operator: In
                      values:
                        - opentelemetry-demo
                    - key: app.kubernetes.io/name
                      operator: In
                      values:
                        - opensearch
      terminationGracePeriodSeconds: 120
      volumes:
        - name: config
          configMap:
            name: opensearch-config
        - emptyDir: {}
          name: config-emptydir
      enableServiceLinks: true
      initContainers:
        - name: configfile
          image: "opensearchproject/opensearch:2.19.0"
          imagePullPolicy: "IfNotPresent"
          command:
            - sh
            - -c
            - |
              #!/usr/bin/env bash
              cp -r /tmp/configfolder/*  /tmp/config/
          resources: {}
          volumeMounts:
            - mountPath: /tmp/config/
              name: config-emptydir
            - name: config
              mountPath: /tmp/configfolder/opensearch.yml
              subPath: opensearch.yml
      containers:
        - name: "opensearch"
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 1000

          image: "opensearchproject/opensearch:2.19.0"
          imagePullPolicy: "IfNotPresent"
          readinessProbe:
            failureThreshold: 3
            periodSeconds: 5
            tcpSocket:
              port: 9200
            timeoutSeconds: 3
          startupProbe:
            failureThreshold: 30
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 9200
            timeoutSeconds: 3
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
            - name: metrics
              containerPort: 9600
          resources:
            limits:
              memory: 1100Mi
            requests:
              cpu: 1000m
              memory: 100Mi
          env:
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: discovery.seed_hosts
              value: "opensearch-cluster-master-headless"
            - name: cluster.name
              value: "demo-cluster"
            - name: network.host
              value: "0.0.0.0"
            - name: OPENSEARCH_JAVA_OPTS
              value: "-Xms300m -Xmx300m"
            - name: node.roles
              value: "master,ingest,data,remote_cluster_client,"
            - name: discovery.type
              value: "single-node"
            - name: bootstrap.memory_lock
              value: "true"
            - name: DISABLE_INSTALL_DEMO_CONFIG
              value: "true"
            - name: DISABLE_SECURITY_PLUGIN
              value: "true"
          volumeMounts:
            - name: config-emptydir
              mountPath: /usr/share/opensearch/config/opensearch.yml
              subPath: opensearch.yml
